{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv(\"resources/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a subset of mnist\n",
    "\n",
    "data = mnist[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "X = data.drop(columns='label')\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalazing the Data \n",
    "\n",
    "X = X / 255.0\n",
    "y = y.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a binary problem by defining the ground truth ('label') as a set of single and double numbers\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if (y[i]%2==0):\n",
    "        \n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def for visualazing a single imaze from our dataset\n",
    "\n",
    "def viz(n):\n",
    "    number = X.iloc[n, :]\n",
    "    number.shape\n",
    "    number = number.values.reshape(28,28)\n",
    "    plt.imshow(number, cmap='gray')\n",
    "    plt.title(\"Digit\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scaling our data into 0 and 1 \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "X = mm.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deviting our data into train and test set to perform our SVM model.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will perform PCA in our X_train and X_test to reduse dimensions. We must keep 90% of our information\n",
    "#So to achieve that we perform this:\n",
    "\n",
    "pca = PCA(0.9)\n",
    "pca.fit(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we see if we reduse our dimensions from 784 to 87 we can work much faster and still get more than 90% of our data\n",
    "\n",
    "pca = PCA(n_components=86)\n",
    "# We apply the dimensional reduction in both X_train and X_test \n",
    "\n",
    "X_trainpca = pca.fit_transform(X_train)\n",
    "X_testpca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot using t-SNE our data to see how the train test is:\n",
    "view = TSNE(n_components=2, random_state=123).fit_transform(X_trainpca)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(view[:,0], view[:,1], c=y_train, alpha=0.5)\n",
    "plt.xlabel('t-SNE-1')\n",
    "plt.ylabel('t-SNE-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparametrs for our model:\n",
    "paramC = [0.001, 0.01, 0.1,  5, 10]\n",
    "gamm = ['auto','scale']\n",
    "deg = [3,6,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with linear kernel:\n",
    "Cl=[]\n",
    "Al=[]\n",
    "Atl=[]\n",
    "for i in paramC:\n",
    "    start = time()\n",
    "    clf = svm.SVC(kernel = 'linear', C=i)\n",
    "    clf.fit(X_trainpca, y_train)\n",
    "    accu = round(accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "    acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "    end = time()\n",
    "    Cl.append(i)\n",
    "    Al.append(accu*100)\n",
    "    Atl.append(acct*100)\n",
    "    print(\"Done in=\", (end-start)//1,\"   Accuracy score=\",accu*100,\"Î‘ccuracy Test\",acct*100,\"for C=\",i,acct*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for Linear Kernel\n",
    "tl=[0.43,0.30,0.23,1.23,1.54]\n",
    "resultslin = pd.DataFrame({'time(s) ' : tl,\n",
    "                         'C' : Cl,\n",
    "                        \"Accuracy Score Train\" : Al,\n",
    "                          \"Accuracy Score Test\" : Atl},\n",
    "                        columns=['time(s) ','C',\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultslin.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for linear kernel \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(resultslin[\"C\"], resultslin[\"Accuracy Score Train\"])\n",
    "plt.plot(resultslin[\"C\"], resultslin[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Kernel Linear\")\n",
    "plt.ylim(60,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with polynomial kernel:\n",
    "Cp=[]\n",
    "Gp=[]\n",
    "Dp=[]\n",
    "Ap=[]\n",
    "Apt=[]\n",
    "for i in paramC:\n",
    "    for k in gamm:\n",
    "        for j in deg:\n",
    "            start = time()\n",
    "            clf = svm.SVC(kernel = 'poly', C=i, gamma=k,degree=j)\n",
    "            clf.fit(X_trainpca, y_train)\n",
    "            acc = round( accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "            acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "            end = time()\n",
    "            Cp.append(i)\n",
    "            Gp.append(k)\n",
    "            Dp.append(j)\n",
    "            Ap.append((acc*100))\n",
    "            Apt.append(acct*100)\n",
    "            print(\"Done in=\", (end-start)//1,\"Accuracy score=\",acc*100,\"Accuracy Test\",acct*100,\"for C=\",i,\"for gamma=\",k,\" for degree=\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for Polynomial Kernel\n",
    "tpo=[1.20,1.14,0.35,0.36,0.46,1.19,1.17,1.19,1.19,1.12,1.17,1.12,0.33,0.40,0.43,1.04,1.12,0.25,1.02,1.12,0.22,0.45,1.02,0.25,0.50,0.40,0.08,0.24,0.23]\n",
    "resultspoly = pd.DataFrame({'time(s) ':tpo,\n",
    "                           'C' : Cp,\n",
    "                           'Gamma' : Gp,\n",
    "                           \"Degree\" :Dp,\n",
    "                           \"Accuracy Score Train\" : Ap,\n",
    "                           \"Accuracy Score Test\":Apt},\n",
    "                        columns=['time(s) ','C','Gamma',\"Degree\",\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultspoly.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for Polynomial Kernel \n",
    "plt.figure(figsize=(19,6))\n",
    "\n",
    "plt.subplot(131)\n",
    "D1 = resultspoly[resultspoly['Degree']==3]\n",
    "plt.plot(D1[\"C\"], D1[\"Accuracy Score Train\"])\n",
    "plt.plot(D1[\"C\"], D1[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 3\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(132)\n",
    "D2 = resultspoly[resultspoly['Degree']==6]\n",
    "plt.plot(D2[\"C\"], D2[\"Accuracy Score Train\"])\n",
    "plt.plot(D2[\"C\"], D2[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 6\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(133)\n",
    "D3 = resultspoly[resultspoly['Degree']==8]\n",
    "plt.plot(D3[\"C\"], D3[\"Accuracy Score Train\"])\n",
    "plt.plot(D3[\"C\"], D3[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 8\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with RBF  kernel:\n",
    "\n",
    "Cr=[]\n",
    "Gr=[]\n",
    "Ar=[]\n",
    "Atr=[]\n",
    "for i in paramC:\n",
    "    for k in gamm:\n",
    "        start1 = time()\n",
    "        clf = svm.SVC(kernel = 'rbf', C=i, gamma=k)\n",
    "        clf.fit(X_trainpca, y_train)\n",
    "        accu = round(accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "        acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "        end1 = time()\n",
    "        Cr.append(i)\n",
    "        Gr.append(k)\n",
    "        Ar.append((accu*100))\n",
    "        Atr.append(acct*100)        \n",
    "        print(\"Done in=\", (end1-start1)//1,\"Accuracy score Train=\",accu*100,\"Accuracy Score Test\",acct*100,\"for C=\",i,\"for gamma=\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for RBF Kernel\n",
    "\n",
    "tr=[1.09,1.13,1.05,1.06,0.37,0.37,0.13,0.22,0.18,0.18]\n",
    "resultsrbf = pd.DataFrame({'time(s) ' : tr,\n",
    "                         'C' : Cr,\n",
    "                        'Gamma' : Gr ,\n",
    "                       \"Accuracy Score Train\" : Ar,\n",
    "                          \"Accuracy Score Test\":Atr},\n",
    "                        columns=['time(s) ','C', 'Gamma',\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsrbf.sort_values(\"Accuracy Score Test\",ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for RBF kernel \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "gam1 = resultsrbf[resultsrbf['Gamma']==\"auto\"]\n",
    "plt.plot(gam1[\"C\"], gam1[\"Accuracy Score Train\"])\n",
    "plt.plot(gam1[\"C\"], gam1[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Auto\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(122)\n",
    "gam2 = resultsrbf[resultsrbf['Gamma']==\"scale\"]\n",
    "plt.plot(gam2[\"C\"], gam2[\"Accuracy Score Train\"])\n",
    "plt.plot(gam2[\"C\"], gam2[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Scale\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for the Best Accuracy Scores\n",
    "\n",
    "Kernel = [\"Linear\", \"Polynomial\",\"RBF\"]\n",
    "timeer = [1.10, 1.38,1.32]\n",
    "C = [0.01,0.1,10]\n",
    "G = [\"-\",\"scale\",\"scale\"]\n",
    "D = [\"-\",\"3\",\"-\"]\n",
    "As =[88.32,96.43,99.97]\n",
    "At= [88.38,94.75,97.85]\n",
    "results12 = pd.DataFrame({'Kernel':Kernel,\n",
    "                          'Time':timeer,\n",
    "                        'C' : C,\n",
    "                        'Gamma' : G ,\n",
    "                        'Degree' : D,\n",
    "                         \"Accuracy Score Train\":As,\n",
    "                         \"Accuracy Score Test\":At,},\n",
    "                        columns=['Kernel','Time','C', 'Gamma','Degree',\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will see the results for our best kernel for both train and test set. \n",
    "clf = svm.SVC(kernel=\"rbf\", C=10,gamma=\"scale\")\n",
    "clf.fit(X_trainpca, y_train)\n",
    "y_train_pred = clf.predict(X_trainpca)\n",
    "y_test_pred = clf.predict(X_testpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(accuracy_score(y_train,y_train_pred),4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(accuracy_score(y_test,y_test_pred),4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for X_train\n",
    "\n",
    "CMTrain = pd.DataFrame(confusion_matrix(y_true=y_train,y_pred=y_train_pred),\n",
    "                  columns=pd.MultiIndex.from_product([[\"Prediction\"],['Negative',\"Positive\"]]),\n",
    "                  index=pd.MultiIndex.from_product([[\"Actual\"],[\"Negative\",\"Positive\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for X_test\n",
    "CMTest = pd.DataFrame(confusion_matrix(y_test,y_test_pred),\n",
    "                  columns=pd.MultiIndex.from_product([[\"Prediction\"],['Negative',\"Positive\"]]),\n",
    "                  index=pd.MultiIndex.from_product([[\"Actual\"],[\"Negative\",\"Positive\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation for the k-NN classifier\n",
    "X_traind,X_val,y_traind,y_val = train_test_split(X_trainpca,y_train,test_size=0.1,random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-NN classification \n",
    "\n",
    "kn = np.arange(1,30,2)\n",
    "AcValid=[]\n",
    "start=time()\n",
    "for k in kn:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_traind,y_traind)\n",
    "    score = round(knn.score(X_val, y_val),4)\n",
    "    AcValid.append(score*100)\n",
    "    end = time()\n",
    "    print(\"Done in:\",(end-start)//1,\"k=%d, accuracy=%.2f%%\" % (k, score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest Centroid classification \n",
    "metrics=[\"euclidean\",\"manhattan\"]\n",
    "n_param = (0.001,0.01,0.1,1)\n",
    "AcNc=[]\n",
    "start=time()\n",
    "for i in metrics: \n",
    "    for k in n_param:\n",
    "        nc = NearestCentroid(metric=i,shrink_threshold=k)\n",
    "        nc.fit(X_traind,y_traind)\n",
    "        score = round(accuracy_score(y_val,nc.predict(X_val)),4)\n",
    "        AcNc.append(score*100)\n",
    "        end = time()\n",
    "        print(\"Done in:\",(end-start)//1,\"metric =\",i,\"thresholds=\",k ,\"   Accuracy:\",(score *100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_trainpca,y_train)\n",
    "y_testpred = knn.predict(X_testpca)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,knn.predict(X_trainpca))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,knn.predict(X_testpca))*100))\n",
    "print(classification_report(y_test,y_testpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NearestCentroid()\n",
    "nc.fit(X_trainpca,y_train)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,nc.predict(X_trainpca))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,nc.predict(X_testpca))*100))\n",
    "print(classification_report(y_test,nc.predict(X_testpca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA+ LDA method using k-NN classifier.\n",
    "kn=np.arange(1,20,2)\n",
    "co = np.arange(1,700,50)\n",
    "Acc=[]\n",
    "Acct=[]\n",
    "knp=[]\n",
    "for i in co:\n",
    "    \n",
    "    # KPCA with rbf kernel \n",
    "    start = time()\n",
    "    kp = KernelPCA(n_components=i,kernel='rbf')\n",
    "    X_trainkpca = kp.fit_transform(X_train)\n",
    "    X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "    # LDA using n_components as \n",
    "    ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "    X_testl = ld.transform(X_testkpca)\n",
    "    bestT=0\n",
    "    # fiting our model using k-NN classifier \n",
    "    for k in kn:\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_trainl,y_train)\n",
    "    #Calculating accuracy\n",
    "        accTr = round(accuracy_score(y_train,knn.predict(X_trainl)),4)*100\n",
    "        accT = round(accuracy_score(y_test,knn.predict(X_testl)),4)*100\n",
    "        if(accT>bestT):\n",
    "            bestTr=accTr\n",
    "            bestT=accT\n",
    "            knnp=k\n",
    "    Acc.append(bestTr)\n",
    "    Acct.append(bestT)\n",
    "    knp.append(knnp)\n",
    "    end = time()\n",
    "    print(\"Done in: \",(end-start)//1,\"Accuracy train : \",bestTr,\"Accuracy test : \",bestT,\"neighbors:\",knnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for KPCA-LDA for k-NN classification \n",
    "\n",
    "tkp=[0.44,3.38,3.03,3.22,2.35,1.90,2.18,3.45,3.53,3.38,2.22,2.17,4.37,4.20]\n",
    "resultskn = pd.DataFrame({'time(s) ' : tkp,\n",
    "                           \"components\":co,\n",
    "                          \"neighbors\":knp,\n",
    "                       \"Accuracy Score Train\" : Acc,\n",
    "                          \"Accuracy Score Test\":Acct},\n",
    "                        columns=['time(s) ','components',\"neighbors\",\"Accuracy Score Train\",\"Accuracy Score Test\"])\n",
    "resultskn.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA+ LDA method using Nearest Centroid.\n",
    "\n",
    "co = np.arange(1,700,50)\n",
    "Anc=[]\n",
    "Anct=[]\n",
    "for i in co:\n",
    "    start = time()\n",
    "    # KPCA with rbf kernel \n",
    "    kp = KernelPCA(n_components=i,kernel='rbf')\n",
    "    X_trainkpca = kp.fit_transform(X_train)\n",
    "    X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "    # LDA using n_components as \n",
    "    ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "    X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    "    # fiting our model using Nearest Centriod classifier \n",
    "    nc = NearestCentroid()\n",
    "    nc.fit(X_trainl,y_train)\n",
    "    #calculating accuracy \n",
    "    accTr = round(accuracy_score(y_train,nc.predict(X_trainl)),4)*100\n",
    "    accT = round(accuracy_score(y_test,nc.predict(X_testl)),4)*100\n",
    "    Anc.append(accTr)\n",
    "    Anct.append(accT)\n",
    "    end = time()\n",
    "    print(\"Done in: \",(end-start)//1,\"Accuracy train : \",accTr,\"Accuracy test : \",accT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for KPCA-LDA for Nearest centroid classification \n",
    "\n",
    "trn=[0.29,2.88,3.83,3.07,2.18,2.22,3.10,3.12,3.55,3.43,2.13,2.52,4.37,4.42]\n",
    "resultsnc = pd.DataFrame({'time(s) ' : trn,\n",
    "                           \"components\":co,\n",
    "                       \"Accuracy Score Train\" : Anc,\n",
    "                          \"Accuracy Score Test\":Anct},\n",
    "                        columns=['time(s) ',\"components\",\"Accuracy Score Train\",\"Accuracy Score Test\"])\n",
    "resultsnc.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#KPCA+LDA ploting for accuracy scores using k-NN classifier\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(resultskn[\"components\"], resultskn[\"Accuracy Score Train\"])\n",
    "plt.plot(resultskn[\"components\"], resultskn[\"Accuracy Score Test\"])\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"KPCA+LDA k-NN\")\n",
    "plt.ylim(40,100)\n",
    "plt.plot()\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "\n",
    "#KPCA+LDA ploting for accuracy scores using Nearest Centroid classifier\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(resultsnc[\"components\"], resultsnc[\"Accuracy Score Train\"])\n",
    "plt.plot(resultsnc[\"components\"], resultsnc[\"Accuracy Score Test\"])\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"KPCA+LDA Nearest Centroid\")\n",
    "plt.ylim(40,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # KPCA + LDA k-NN classifier \n",
    "kp = KernelPCA(n_components=651,kernel='rbf')\n",
    "X_trainkpca = kp.fit_transform(X_train)\n",
    "X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "\n",
    "ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    " \n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_trainl,y_train)\n",
    "    #Calculating accuracy\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,knn.predict(X_trainl))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,knn.predict(X_testl))*100))\n",
    "print(classification_report(y_test,knn.predict(X_testl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # KPCA + LDA Nearest Centroid \n",
    "kp = KernelPCA(n_components=651,kernel='rbf')\n",
    "X_trainkpca = kp.fit_transform(X_train)\n",
    "X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    "\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X_trainl,y_train)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,nc.predict(X_trainl))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,nc.predict(X_testl))*100))\n",
    "print(classification_report(y_test,nc.predict(X_testl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final results for all the methods. \n",
    "\n",
    "Method = [\"SVM\", \"k-NN\",\"Nearest Centroid\",\"KPCA+LDA k-NN\",\"KPCA+LDA Nearest Centroid\"]\n",
    "timeer = [1.32,0.54,0.18,4.20,4.42]\n",
    "At = [99.98,98.85,80.83,97.67,97.43]\n",
    "Atest = [98.81,98.28,82.08,95.67,95.80]\n",
    "resultsfinal = pd.DataFrame({'Method':Method,\n",
    "                          'Time(s) ':timeer,\n",
    "                        'Accuracy Train Set' : At,\n",
    "                         \"Accuracy Test Set\":Atest},\n",
    "                        columns=['Method','Time(s) ','Accuracy Train Set',\"Accuracy Test Set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
