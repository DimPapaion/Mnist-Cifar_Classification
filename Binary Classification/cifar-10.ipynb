{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = unpickle(\"resources/cifar-10-batches-py/data_batch_1\")\n",
    "data2 = unpickle(\"resources/cifar-10-batches-py/data_batch_2\")\n",
    "data3 = unpickle(\"resources/cifar-10-batches-py/data_batch_3\")\n",
    "data4 = unpickle(\"resources/cifar-10-batches-py/data_batch_4\")\n",
    "data5 = unpickle(\"resources/cifar-10-batches-py/data_batch_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datam = unpickle(\"resources/cifar-10-batches-py/batches.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(data1[b'data'])\n",
    "Y1 = pd.DataFrame(data1[b'labels'])\n",
    "X2 = pd.DataFrame(data2[b'data'])\n",
    "Y2 = pd.DataFrame(data2[b'labels'])\n",
    "X3 = pd.DataFrame(data3[b'data'])\n",
    "Y3 = pd.DataFrame(data3[b'labels'])\n",
    "X4 = pd.DataFrame(data4[b'data'])\n",
    "Y4 = pd.DataFrame(data4[b'labels'])\n",
    "X5 = pd.DataFrame(data5[b'data'])\n",
    "Y5 = pd.DataFrame(data5[b'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =pd.concat([X1,X2,X3,X4,X5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.concat([Y1,Y2,Y3,Y4,Y5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting all the truth label and rename the values with the actuall name of subjects reprecented on images \n",
    "\n",
    "Y = np.array(Y)\n",
    "names=[]\n",
    "for i in range(Y.shape[0]):\n",
    "    if Y[i] == 1:\n",
    "        names.append('airplane')\n",
    "    elif Y[i]==2:\n",
    "        names.append(\"automobile\")\n",
    "    elif Y[i]==3:\n",
    "        names.append(\"bird\")\n",
    "    elif Y[i]==4:\n",
    "        names.append('cat')\n",
    "    elif Y[i]==3:\n",
    "        names.append(\"deer\")\n",
    "    elif Y[i]==5:\n",
    "        names.append('dog')   \n",
    "        \n",
    "    elif Y[i]==6:\n",
    "        names.append('frog')    \n",
    "        \n",
    "    elif Y[i]==7:\n",
    "        names.append('horse')\n",
    "    elif Y[i]==7:\n",
    "        names.append('ship')\n",
    "    else:\n",
    "        names.append('truck')\n",
    "names = pd.DataFrame(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping our data.\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting one random image to see how it looks like \n",
    "\n",
    "object1 = X[7, :]\n",
    "object1.shape\n",
    "plt.imshow(object1, interpolation='nearest')\n",
    "plt.title(\"Digit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing the tranformatation FROM RGB to GrayScale\n",
    "\n",
    "XGrey = np.empty_like(X[..., 0])   \n",
    "for i in range(X.shape[0]):\n",
    "    XGrey[i] = cv2.cvtColor(X[i], cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting our result for a random image.\n",
    "\n",
    "object1 = XGrey[7, :]\n",
    "object1.shape\n",
    "plt.imshow(object1,cmap='gray')\n",
    "plt.title(\"Digit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGrey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGrey = pd.DataFrame(XGrey.reshape(50000,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGrey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGrey['label']=names.values\n",
    "cifar10 = pd.DataFrame(XGrey)\n",
    "cols = list(cifar10.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "cifar10 = cifar10[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = cifar10[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cifar10.drop(columns='label')\n",
    "y = cifar10['label']\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax scaling to our data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "Xm = mm.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making our problem Binary. By trying to seperate animals from objects.\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if (y[i]==\"cat\"):\n",
    "        y[i] = 0\n",
    "    elif (y[i]=='bird'):\n",
    "        y[i] = 0\n",
    "    elif (y[i]=='deer'):\n",
    "        y[i] = 0\n",
    "    elif(y[i]=='horse'):\n",
    "        y[i] = 0\n",
    "    elif (y[i]=='dog'):\n",
    "        y[i] = 0\n",
    "    elif(y[i]=='frog'):\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into traing and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xm, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing PCA to reduce asmuch we can our dimensions but with keeping more than 90% information. \n",
    "pca = PCA(0.9)\n",
    "pca.fit(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 76)\n",
    "X_trainpca = pca.fit_transform(X_train)\n",
    "X_testpca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot using t-SNE our data to see how the train test is:\n",
    "view = TSNE(n_components=2, random_state=123).fit_transform(X_trainpca)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(view[:,0], view[:,1], c=y_train, alpha=0.5)\n",
    "plt.xlabel('t-SNE-1')\n",
    "plt.ylabel('t-SNE-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparametrs for our model:\n",
    "paramC = [0.001, 0.01, 0.1, 1, 5]\n",
    "gamm = ['auto','scale']\n",
    "deg = [3, 6, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with linear kernel:\n",
    "Cl=[]\n",
    "Al=[]\n",
    "Atl=[]\n",
    "for i in paramC:\n",
    "    start = time()\n",
    "    clf = svm.SVC(kernel = 'linear', C=i)\n",
    "    clf.fit(X_trainpca, y_train)\n",
    "    accu = round(accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "    acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "    end = time()\n",
    "    Cl.append(i)\n",
    "    Al.append(accu*100)\n",
    "    Atl.append(acct*100)\n",
    "    print(\"Done in=\", (end-start)//1,\"   Accuracy score=\",accu*100,\"Î‘ccuracy Test\",acct*100,\"for C=\",i,acct*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for Linear Kernel\n",
    "tl=[1.07,1.1,1.2,1.9,4.33]\n",
    "resultslin = pd.DataFrame({'time(s) ' : tl,\n",
    "                         'C' : Cl,\n",
    "                        \"Accuracy Score Train\" : Al,\n",
    "                          \"Accuracy Score Test\" : Atl},\n",
    "                        columns=['time(s) ','C',\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultslin.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for linear kernel \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(resultslin[\"C\"], resultslin[\"Accuracy Score Train\"])\n",
    "plt.plot(resultslin[\"C\"], resultslin[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Kernel Linear\")\n",
    "plt.ylim(60,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with polynomial kernel:\n",
    "Cp=[]\n",
    "Gp=[]\n",
    "Dp=[]\n",
    "Ap=[]\n",
    "Apt=[]\n",
    "for i in paramC:\n",
    "    for k in gamm:\n",
    "        for j in deg:\n",
    "            start = time()\n",
    "            clf = svm.SVC(kernel = 'poly', C=i, gamma=k,degree=j)\n",
    "            clf.fit(X_trainpca, y_train)\n",
    "            acc = round( accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "            acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "            end = time()\n",
    "            Cp.append(i)\n",
    "            Gp.append(k)\n",
    "            Dp.append(j)\n",
    "            Ap.append((acc*100))\n",
    "            Apt.append(acct*100)\n",
    "            print(\"Done in=\", (end-start)//1,\"Accuracy score=\",acc*100,\"Accuracy Test\",acct*100,\"for C=\",i,\"for gamma=\",k,\" for degree=\",j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for Polynomial Kernel\n",
    "tpo=[1.42,1.43,1.48,1.4,1.42,1.45,1.42,1.47,1.3,1.38,1.43,1.23,1.38,1.43,1.23,1.38,1.48,1.23,1.33,1.4,1.23,1.33,1.42,1.32,1.32,1.4,1.4,2.15,2.17,2.05]\n",
    "resultspoly = pd.DataFrame({'time(s) ':tpo,\n",
    "                           'C' : Cp,\n",
    "                           'Gamma' : Gp,\n",
    "                           \"Degree\" :Dp,\n",
    "                           \"Accuracy Score Train\" : Ap,\n",
    "                           \"Accuracy Score Test\":Apt},\n",
    "                        columns=['time(s) ','C','Gamma',\"Degree\",\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultspoly.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for Polynomial Kernel \n",
    "plt.figure(figsize=(19,6))\n",
    "\n",
    "plt.subplot(131)\n",
    "D1 = resultspoly[resultspoly['Degree']==3]\n",
    "plt.plot(D1[\"C\"], D1[\"Accuracy Score Train\"])\n",
    "plt.plot(D1[\"C\"], D1[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 3\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(132)\n",
    "D2 = resultspoly[resultspoly['Degree']==6]\n",
    "plt.plot(D2[\"C\"], D2[\"Accuracy Score Train\"])\n",
    "plt.plot(D2[\"C\"], D2[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 6\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(133)\n",
    "D3 = resultspoly[resultspoly['Degree']==8]\n",
    "plt.plot(D3[\"C\"], D3[\"Accuracy Score Train\"])\n",
    "plt.plot(D3[\"C\"], D3[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Degree = 8\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start building our svm with RBF  kernel:\n",
    "\n",
    "Cr=[]\n",
    "Gr=[]\n",
    "Ar=[]\n",
    "Atr=[]\n",
    "for i in paramC:\n",
    "    for k in gamm:\n",
    "        start1 = time()\n",
    "        clf = svm.SVC(kernel = 'rbf', C=i, gamma=k)\n",
    "        clf.fit(X_trainpca, y_train)\n",
    "        accu = round(accuracy_score(y_train, clf.predict(X_trainpca)),4)\n",
    "        acct = round( accuracy_score(y_test, clf.predict(X_testpca)),4)\n",
    "        end1 = time()\n",
    "        Cr.append(i)\n",
    "        Gr.append(k)\n",
    "        Ar.append((accu*100))\n",
    "        Atr.append(acct*100)        \n",
    "        print(\"Done in=\", (end1-start1)//1,\"Accuracy score Train=\",accu*100,\"Accuracy Score Test\",acct*100,\"for C=\",i,\"for gamma=\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for RBF Kernel\n",
    "\n",
    "tr=[1.57,1.57,1.35,1.38,1.18,1.25,1.05,1.08,1.17,1.32]\n",
    "resultsrbf = pd.DataFrame({'time(s) ' : tr,\n",
    "                         'C' : Cr,\n",
    "                        'Gamma' : Gr ,\n",
    "                       \"Accuracy Score Train\" : Ar,\n",
    "                          \"Accuracy Score Test\":Atr},\n",
    "                        columns=['time(s) ','C', 'Gamma',\"Accuracy Score Train\",\"Accuracy Score Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsrbf.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots for RBF kernel \n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "gam1 = resultsrbf[resultsrbf['Gamma']==\"auto\"]\n",
    "plt.plot(gam1[\"C\"], gam1[\"Accuracy Score Train\"])\n",
    "plt.plot(gam1[\"C\"], gam1[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Auto\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.subplot(122)\n",
    "gam2 = resultsrbf[resultsrbf['Gamma']==\"scale\"]\n",
    "plt.plot(gam2[\"C\"], gam2[\"Accuracy Score Train\"])\n",
    "plt.plot(gam2[\"C\"], gam2[\"Accuracy Score Test\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Scale\")\n",
    "plt.ylim(10,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "plt.xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for the Best Accuracy Scores\n",
    "\n",
    "Kernel = [\"Linear\", \"Polynomial\",\"RBF\"]\n",
    "timeer = [\"4.33\", \"1.38\",\"1.25\"]\n",
    "C = [5,0.01,0.1]\n",
    "G = [\"-\",\"scale\",\"scale\"]\n",
    "D = [\"-\",3,\"-\"]\n",
    "As =[67.35,64.32,72.29]\n",
    "results = pd.DataFrame({'Kernel':Kernel,\n",
    "                          'Time':timeer,\n",
    "                        'C' : C,\n",
    "                        'Gamma' : G ,\n",
    "                        'Degree' : D,\n",
    "                         \"Accuracy Score Train\":As},\n",
    "                        columns=['Kernel','Time','C', 'Gamma','Degree',\"Accuracy Score Train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will see the results for our best kernel for both train and test set. \n",
    "clf = svm.SVC(kernel=\"rbf\", C=0.1,gamma=\"scale\")\n",
    "clf.fit(X_trainpca, y_train)\n",
    "#Predictions\n",
    "y_train_pred = clf.predict(X_trainpca)\n",
    "y_test_pred = clf.predict(X_testpca)\n",
    "#Accuracy score\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,y_train_pred)*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,y_test_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for X_train\n",
    "\n",
    "CMTrain = pd.DataFrame(confusion_matrix(y_true=y_train,y_pred=y_train_pred),\n",
    "                  columns=pd.MultiIndex.from_product([[\"Prediction\"],['Negative',\"Positive\"]]),\n",
    "                  index=pd.MultiIndex.from_product([[\"Actual\"],[\"Negative\",\"Positive\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for X_test\n",
    "CMTest = pd.DataFrame(confusion_matrix(y_test,y_test_pred),\n",
    "                  columns=pd.MultiIndex.from_product([[\"Prediction\"],['Negative',\"Positive\"]]),\n",
    "                  index=pd.MultiIndex.from_product([[\"Actual\"],[\"Negative\",\"Positive\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cross validation for the k-NN classifier\n",
    "X_traind,X_val,y_traind,y_val = train_test_split(X_trainpca,y_train,test_size=0.1,random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-NN classification \n",
    "\n",
    "kn = np.arange(1,30,2)\n",
    "AcValid=[]\n",
    "start=time()\n",
    "for k in kn:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_traind,y_traind)\n",
    "    score = round(knn.score(X_val, y_val),4)\n",
    "    AcValid.append(score*100)\n",
    "    end = time()\n",
    "    print(\"Done in:\",(end-start)//1,\"k=%d,  accuracy=%.2f%%\" % (k, score * 100))\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr = [0.03,0.07,0.11,0.15,0.19,0.23,0.28,0.32,0.36,0.40,0.45,0.49,0.53,0.58,1.02]\n",
    "resultsknn = pd.DataFrame({'time(s) ' : Tr,\n",
    "                        'n_Neighbors' : kn ,\n",
    "                       \"Accuracy score\" : AcValid},\n",
    "                        columns=['time(s) ', 'n_Neighbors',\"Accuracy score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsknn.sort_values(\"Accuracy score\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_trainpca,y_train)\n",
    "y_testpred = knn.predict(X_testpca)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,knn.predict(X_trainpca))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,knn.predict(X_testpca))*100))\n",
    "print(classification_report(y_test,knn.predict(X_testpca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NearestCentroid()\n",
    "nc.fit(X_trainpca,y_train)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,nc.predict(X_trainpca))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,nc.predict(X_testpca))*100))\n",
    "print(classification_report(y_test,nc.predict(X_testpca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA+ LDA method using k-NN classifier.\n",
    "\n",
    "co = np.arange(1,100,10)\n",
    "Acc=[]\n",
    "Acct=[]\n",
    "for i in co:\n",
    "    \n",
    "    # KPCA with rbf kernel \n",
    "    start = time()\n",
    "    kp = KernelPCA(n_components=i,kernel='rbf')\n",
    "    X_trainkpca = kp.fit_transform(X_train)\n",
    "    X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "    # LDA using n_components as \n",
    "    ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "    X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    "    # fiting our model using k-NN classifier \n",
    "    knn = KNeighborsClassifier(n_neighbors=17)\n",
    "    knn.fit(X_trainl,y_train)\n",
    "    #Calculating accuracy\n",
    "    accTr = round(accuracy_score(y_train,knn.predict(X_trainl)),4)*100\n",
    "    accT = round(accuracy_score(y_test,knn.predict(X_testl)),4)*100\n",
    "    Acc.append(accTr)\n",
    "    Acct.append(accT)\n",
    "    end = time()\n",
    "    print(\"Done in: \",(end-start)//1,\"Accuracy train : \",accTr,\"Accuracy test : \",accT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for KPCA-LDA for k-NN classification \n",
    "\n",
    "tkp=[0.588.13,9.57,10.30,10.38,10.10,10.20,10,10.33,10.56]\n",
    "resultskn = pd.DataFrame({'time(s) ' : tkp,\n",
    "                           \"components\":co,\n",
    "                       \"Accuracy Score Train\" : Acc,\n",
    "                          \"Accuracy Score Test\":Acct},\n",
    "                        columns=['time(s) ','components',\"Accuracy Score Train\",\"Accuracy Score Test\"])\n",
    "resultskn.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPCA+ LDA method using Nearest Centroid.\n",
    "\n",
    "co = np.arange(1,100,10)\n",
    "Anc=[]\n",
    "Anct=[]\n",
    "for i in co:\n",
    "    start = time()\n",
    "    # KPCA with rbf kernel \n",
    "    kp = KernelPCA(n_components=i,kernel='rbf')\n",
    "    X_trainkpca = kp.fit_transform(X_train)\n",
    "    X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "    # LDA using n_components as \n",
    "    ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "    X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "    X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    "    # fiting our model using Nearest Centriod classifier \n",
    "    nc = NearestCentroid()\n",
    "    nc.fit(X_trainl,y_train)\n",
    "    #calculating accuracy \n",
    "    accTr = round(accuracy_score(y_train,nc.predict(X_trainl)),4)*100\n",
    "    accT = round(accuracy_score(y_test,nc.predict(X_testl)),4)*100\n",
    "    Anc.append(accTr)\n",
    "    Anct.append(accT)\n",
    "    end = time()\n",
    "    print(\"Done in: \",(end-start)//1,\"Accuracy train : \",accTr,\"Accuracy test : \",accT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for KPCA-LDA for Nearest centroid classification \n",
    "\n",
    "trn=[1.07,10.30,9.25,10.07,10.45,10.25,10.31,10,10.37]\n",
    "resultsnc = pd.DataFrame({'time(s) ' : trn,\n",
    "                           \"components\":co,\n",
    "                       \"Accuracy Score Train\" : Anc,\n",
    "                          \"Accuracy Score Test\":Anct},\n",
    "                        columns=['time(s) ',\"components\",\"Accuracy Score Train\",\"Accuracy Score Test\"])\n",
    "resultsnc.sort_values(\"Accuracy Score Test\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting plots\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#KPCA+LDA ploting for accuracy scores using k-NN classifier\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(resultskn[\"components\"], resultskn[\"Accuracy Score Train\"])\n",
    "plt.plot(resultskn[\"components\"], resultskn[\"Accuracy Score Test\"])\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"KPCA+LDA k-NN\")\n",
    "plt.ylim(40,100)\n",
    "plt.plot()\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])\n",
    "\n",
    "#KPCA+LDA ploting for accuracy scores using Nearest Centroid classifier\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(resultsnc[\"components\"], resultsnc[\"Accuracy Score Train\"])\n",
    "plt.plot(resultsnc[\"components\"], resultsnc[\"Accuracy Score Test\"])\n",
    "plt.xlabel('components')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"KPCA+LDA Nearest Centroid\")\n",
    "plt.ylim(40,100)\n",
    "plt.legend(['Accuracy Train','Accuracy Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # KPCA + LDA k-NN classifier \n",
    "kp = KernelPCA(n_components=31,kernel='rbf')\n",
    "X_trainkpca = kp.fit_transform(X_train)\n",
    "X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "\n",
    "ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    " \n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_trainl,y_train)\n",
    "    #Calculating accuracy\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,knn.predict(X_trainl))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,knn.predict(X_testl))*100))\n",
    "print(classification_report(y_test,knn.predict(X_testl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # KPCA + LDA Nearest Centroid \n",
    "kp = KernelPCA(n_components=81,kernel='rbf')\n",
    "X_trainkpca = kp.fit_transform(X_train)\n",
    "X_testkpca = kp.transform(X_test)\n",
    "    \n",
    "ld = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_trainl = ld.fit_transform(X_trainkpca,y_train)\n",
    "X_testl = ld.transform(X_testkpca)\n",
    "    \n",
    "\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X_trainl,y_train)\n",
    "print('Accuracy Score on Train Set: {:.2f}%'.format(accuracy_score(y_train,nc.predict(X_trainl))*100))\n",
    "print('Accuracy Score on Test Set: {:.2f}%'.format(accuracy_score(y_test,nc.predict(X_testl))*100))\n",
    "print(classification_report(y_test,nc.predict(X_testl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final results for all the methods. \n",
    "\n",
    "Method = [\"SVM\", \"k-NN\",\"Nearest Centroid\",\"KPCA+LDA k-NN\",\"KPCA+LDA Nearest Centroid\"]\n",
    "timeer = [1.25,0.23,0.18,9.47,8.02]\n",
    "At = [72.29,73.55,64.28,70.13,68.46]\n",
    "Atest = [70.86,67.81,64.21,64.64,67.67]\n",
    "resultsfinal = pd.DataFrame({'Method':Method,\n",
    "                          'Time(s) ':timeer,\n",
    "                        'Accuracy Train Set' : At,\n",
    "                         \"Accuracy Test Set\":Atest},\n",
    "                        columns=['Method','Time(s) ','Accuracy Train Set',\"Accuracy Test Set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
